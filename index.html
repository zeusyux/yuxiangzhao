<html>
    <head>
        <link rel="stylesheet" type="text/css" href="assets/font-awesome-4.7.0/css/font-awesome.min.css">
        <link rel="stylesheet" type="text/css" href="assets/academicons-1.8.6/css/academicons.min.css">
        <link rel="stylesheet" type="text/css" href="assets/style.css">
        <link rel="icon" type="image/png" href="assets/figures/icon.png">
        <link rel="apple-touch-icon" type="image/png" href="assets/figures/icon.png">
        <title>Yuxiang Zhao's Homepage </title>
    </head>
    
    <body><table border=0 width=1000px align=center><tr><td>
    
        <td valign="top">

        <br>
        <table style="font-size: 11pt;" border=0 width=100%>
            <tr>
                <td> 
                      <p style="text-align:left;font-size: 25pt;">
                        <name>Yuxiang Zhao</name>
                      </p>
                      <p style="text-align:left;font-size: 13pt;">
                        <font> 
                            Computer Vision Researcher<br>
                            Alibaba Group<br>
                            <a style="font-size: 13pt" href="mailto:zeusyux@gmail.com">E-mail</a> &nbsp/&nbsp
                            <a style="font-size: 13pt" href="assets/cv/CV_Xuan.pdf">CV</a> &nbsp/&nbsp
                            <a style="font-size: 13pt" href="https://scholar.google.com.hk/citations?user=pWzvK20AAAAJ&hl=zh-CN">Google Scholar</a> &nbsp/&nbsp
                            <a style="font-size: 13pt" href="https://zeusyux.github.io/yuxiangzhao"> Github </a> 
                        </font>
                      </p>
                </td>
                <td width = "20%">
                    <img src="assets/figures/avatar1.png" style="width: 100%; height: auto;">
                        </td>
            </tr>
        </table> 

        
        <!-- <font face="helvetica, ariel, 'sans serif'">  -->
        <h2>Biography</h2>
        <p style="line-height:15pt; font-size: 13pt; text-align: justify; margin:10pt 0px">
          Hi, I'm Yuxiang Zhao (赵煜翔). I'm a computer vision researcher at Alibaba Group, exploring the boundaries of human-like multimodal understanding and generation in a scalable way. Previously, I spent three wonderful years at Tencent Hunyuan&AI Lab and International Digital Economy Academy (IDEA), leading human-centric perception and generation research team. I obtained my Ph.D. from the Department of Computer Science and Engineering, the Chinese University of Hong Kong, supervised by Prof. Qiang Xu. I was a visiting scholar in the Robotics Institute, Carnegie Mellon University. My research aims to build multi-modal, human-like intelligent agents in a scalable way, especially by training Large Motion Models to capture, understand, interact with, and generate the motion of humans, animals, and the world. Specifically,
        </p>
        <!-- </font>        -->

        <h2>News</h2>
        <ul style="font-size: 14pt; text-align: justify;margin:10pt 0px"> 
        <li><strong>[09/2025]</strong> <font color="black" size="3"> We release a unified image/video editing/generation framework, <a href="http://editverse.s3-website-us-east-1.amazonaws.com/">EditVerse</a>. </font> </li>
        <li><strong>[06/2025]</strong> <font color="black" size="3"> <a href="https://fulldit.github.io/">FullDiT</a> (a multi-task video generation model based on full-attention) is accepted to ICCV 2025, see you in Hawai'i!</font> </li>
        <li><strong>[05/2025]</strong> <font color="black" size="3"> We are hosting the CVPR 2025 Workshop on <a href="https://cvpr25-edge.github.io/">Efficient and On-Device Generation (EDGE)</a>. </font> </li>
        <li><strong>[04/2025]</strong> <font color="black" size="3"> Start an internship in <a href="https://research.adobe.com/">Adobe Research</a> with <a href="https://sites.google.com/view/sooyekim">Soo Ye Kim</a> and <a href="https://scholar.google.com/citations?user=R0bnqaAAAAAJ&hl=en">Zhe Lin</a>. </font> </li>
        <li><strong>[04/2025]</strong> <font color="black" size="3"> <a href="https://arxiv.org/abs/2503.05639">VideoPainter</a> and <a href="https://arxiv.org/abs/2504.12240">Cobra</a> are accepted to SIGGRAPH 2025.</font> </li>
        </ul> 

        <h2>Selected Publications</h2>
        <p style="margin:-20pt 0px">
          <br/>
          * equal contribution
          <table style="border-collapse:separate; border-spacing:0px 35px;" cellspacing="8">
          <tbody>

            <tr>
              <td width="30%">
                <img width="250" height="150" src="assets/figures/editverse.png">
              </td>
              <td>
                <div class="title">
                  EditVerse: Unifying Image and Video Editing and Generation with In-Context Learning
                </div>
                <div class="author">
                  <span class="me">Xuan Ju</span>,
                  <a href="https://scholar.google.com/citations?user=yRwZIN8AAAAJ&hl=zh-CN">Tianyu Wang</a>,
                  <a href="https://yzhouas.github.io/">Yuqian Zhou</a>,
                  <a href="https://sites.google.com/site/hezhangsprinter/">He Zhang</a>,
                  <a href="https://qliu24.github.io/">Qing Liu</a>,
                  <a href="https://www.nxzhao.com/">Nanxuan Zhao</a>,
                  <a href="https://zzutk.github.io/">Zhifei Zhang</a>,
                  <a href="https://yijunmaverick.github.io/">Yijun Li</a>,
                  <a href="https://caiyuanhao1998.github.io/">Yuanhao Cai</a>,
                  <a href="https://www.shaotengliu.com/">Shaoteng Liu</a>,
                  <a href="https://scholar.google.com/citations?user=UI10l34AAAAJ&hl=en">Daniil Pakhomov</a>,
                  <a href="https://sites.google.com/site/zhelin625/">Zhe Lin</a>,
                  <a href="https://sites.google.com/view/sooyekim">Soo Ye Kim</a>,
                  <a href="https://www.cse.cuhk.edu.hk/people/faculty/qiang-xu/">Qiang Xu</a>.

                </div>
                <div class="conf">
                  Under Review
                </div>
                <div>
                  <span class="tag"> <a href="http://editverse.s3-website-us-east-1.amazonaws.com/" target="_blank">Project</a> </span> /
                  <span class="tag"> <a href="https://arxiv.org/abs/2509.20360" target="_blank">arXiv</a> </span> /
                  <span class="tag"> <a href="https://github.com/cure-lab/EditVerse" target="_blank">Code</a> </span> /
                  <span class="tag"> <a href="https://huggingface.co/datasets/sooyek/EditVerseBench" target="_blank">Benchmark</a> </span> /
                  <span class="tag"> <a href="https://docs.google.com/presentation/d/1dBg3lZDFa8mRRIrOVEU_xDgzedufbwzr/edit?usp=sharing&ouid=100286465794673637256&rtpof=true&sd=true" target="_blank">Slides</a> </span> / 
                  <span class="tag"> <a href="http://editverse.s3-website-us-east-1.amazonaws.com/comparison.html" target="_blank">Full Comparison</a> </span>
                </div>
              </td>
            </tr>
            

            <tr>
              <td width="30%">
                <img width="250" height="130" src="assets/figures/fulldit.png">
              </td>
              <td>
                <div class="title">
                  FullDiT: Multi-Task Video Generative Foundation Model with Full Attention
                </div>
                <div class="author">
                  <span class="me">Xuan Ju</span>,
                  <a href="https://ywcmaike.github.io/">Weicai Ye</a>,
                  <a href="https://liuquande.github.io/">Quande Liu</a>,
                  <a href="https://openreview.net/profile?id=~Qiulin_Wang1">Qiulin Wang</a>,
                  <a href="https://xinntao.github.io/">Xintao Wang</a>,
                  <a href="https://scholar.google.com/citations?user=P6MraaYAAAAJ&hl=en">Pengfei Wan</a>,
                  <a href="https://openreview.net/profile?id=~Di_ZHANG3">Di Zhang</a>,
                  <a href="https://scholar.google.com/citations?user=PXO4ygEAAAAJ">Kun Gai</a>,
                  <a href="https://scholar.google.com/citations?user=eSiKPqUAAAAJ&hl=zh-CN">Qiang Xu</a>.
                </div>
                <div class="conf">
                  International Conference on Computer Vision (ICCV), 2025
                </div>
                <div>
                  <span class="tag"> <a href="https://fulldit.github.io/" target="_blank">Project</a> </span> /
                  <span class="tag"> <a href="https://arxiv.org/pdf/2503.19907v1" target="_blank">arXiv</a> </span> /
                  <span class="tag"> <a href="https://fulldit.github.io/videos/presentation.mp4" target="_blank">Video</a> </span> /
                  <span class="tag"> <a href="https://huggingface.co/datasets/KwaiVGI/FullBench" target="_blank">Data</a> </span>
                </div>
              </td>
            </tr>
            

            
            <tr>
              <td width="30%">
                <img width="250" height="150" src="assets/figures/teletubbies.jpg">
              </td>
              <td>
                <div class="title">
                  	Teletubbies: On Design Choices of Scaling Autoregressive Models for Image Generation
                </div>
                <div class="author">
                  <a href="https://yushi-hu.github.io/">Yushi Hu*</a>,
                  <span class="me">Xuan Ju*</span>,
                  <a href="https://ma-xu.github.io/">Xu Ma*</a>,
                  <a href="https://yujun-shi.github.io/">Yujun Shi*</a>,
                  <a href="https://scholar.google.com/citations?user=u4olrOcAAAAJ&hl=en">Xiaoliang Dai</a>,
                  <a href="https://scholar.google.com/citations?user=eqQQkM4AAAAJ&hl=en">Peizhao Zhang</a>,
                  <a href="https://scholar.google.com/citations?user=R8vOkZYAAAAJ&hl=en">Jialiang Wang</a>,
                  <a href="https://sekunde.github.io/">Ji Hou</a>,
                  <a href="https://scholar.google.com.tw/citations?user=yeAeAhsAAAAJ&hl=zh-TW">Yen-Cheng Liu</a>,
                  <a href="https://scholar.google.com.hk/citations?hl=zh-CN&user=BOI3opEAAAAJ">Haochen Zhang</a>,
                  <a href="https://scholar.google.com/citations?user=_-vYZ68AAAAJ&hl=en">Tao Xu</a>,
                  <a href="https://scholar.google.com/citations?user=dgN8vtwAAAAJ&hl=zh-CN">Felix Juefei-Xu</a>,
                  <a href="https://scholar.google.com/citations?user=fpUICd0AAAAJ&hl=en">Ching-Yao Chuang</a>,
                  <a href="https://zechenghe.github.io/">Zecheng He</a>,
                  <a href="https://potatotian.github.io/">Junjiao Tian</a>,
                  <a href="https://scholar.google.com/citations?user=u-UDZcsAAAAJ&hl=en">Tingbo Hou</a>,
                  <a href="https://www.linkedin.com/in/p%C3%A9ter-vajda-9a03aaa/">Peter Vajda</a>,
                  <a href="https://scholar.google.com/citations?user=eSiKPqUAAAAJ&hl=zh-CN">Qiang Xu</a>,
                  <a href="https://scholar.google.com/citations?user=h-JEcQ8AAAAJ&hl=en">Yun Fu</a>,
                  <a href="https://scholar.google.com/citations?user=dJoAVvAAAAAJ&hl=en">Vincent Y. F. Tan</a>,
                  <a href="https://scholar.google.com/citations?user=exS-GecAAAAJ&hl=zh-CN">Mari Ostendorf</a>,
                  <a href="https://nasmith.github.io/">Noah A. Smith</a>,
                  <a href="https://scholar.google.com/citations?user=G03EzSMAAAAJ&hl=en">Zijian He</a>,
                  <a href="https://scholar.google.com/citations?user=JdE_LFYAAAAJ&hl=zh-CN">Sam Tsai</a>,
                  <a href="https://kunpengli1994.github.io/">Kunpeng Li</a>,
                  <a href="https://chihyaoma.github.io/">Chih-Yao Ma</a>.
                </div>
              </td>
            </tr>
            
            
            <tr>
              <td width="30%">
                <img width="250" height="150" src="assets/figures/miradata.jpeg">
              </td>
              <td>
                <div class="title">
                  MiraData: A Large-Scale Video Dataset with Long Durations and Structured Captions
                </div>
                <div class="author">
                  <span class="me">Xuan Ju*</span>,
                  <a href="https://scholar.google.com/citations?user=uRCc-McAAAAJ&hl=zh-TW">Yiming Gao*</a>,
                  <a href="https://zzyfd.github.io/#/">Zhaoyang Zhang*</a>,
                  <a href="https://github.com/jiangyzy">Ziyang Yuan</a>,
                  <a href="https://xinntao.github.io/">Xintao Wang</a>,
                  <a href="https://ailingzeng.site/">Ailing Zeng</a>,
                  <a href="http://xiongyu.me/">Yu Xiong</a>,
                  <a href="https://scholar.google.com/citations?user=eSiKPqUAAAAJ&hl=zh-CN">Qiang Xu</a>,
                  <a href="https://www.linkedin.com/in/yingshanprofile">Ying Shan</a>.
                </div>
                <div class="conf">
                  Conference on Neural Information Processing Systems (<b>NeurIPS</b>), 2024
                </div>
                <div>
                  <span class="tag"> <a href="https://mira-space.github.io/" target="_blank">Project</a> </span> /
                  <span class="tag"> <a href="https://arxiv.org/pdf/2407.06358" target="_blank">arXiv</a> </span> /
                  <span class="tag"> <a href="https://www.youtube.com/watch?v=3G0p7Jo3GYM" target="_blank">Video</a> </span> /
                  <span class="tag"> <a href="https://github.com/mira-space/MiraData" target="_blank">Code</a> </span> /
                  <span class="tag"> <a href="https://github.com/mira-space/MiraData" target="_blank">Data</a> </span>
                  <img alt="GitHub Repo stars" src="https://img.shields.io/github/stars/mira-space/MiraData">
                </div>
              </td>
            </tr>
            

            
            <tr>
              <td width="30%">
                <img width="250" height="150" src="assets/figures/brushnet.png">
              </td>
              <td>
                <div class="title">
                  BrushNet : A Plug-and-Play Image Inpainting Model with Decomposed Dual-Branch Diffusion
                </div>
                <div class="author">
                  <span class="me">Xuan Ju</span>,
                  <a href="https://alvinliu0.github.io/">Xian Liu</a>,
                  <a href="https://xinntao.github.io/">Xiantao Wang</a>,
                  <a href="https://yxbian23.github.io/">Yuxuan Bian</a>,
                  <a href="https://www.linkedin.com/in/yingshanprofile">Ying Shan</a>,
                  <a href="https://scholar.google.com/citations?user=eSiKPqUAAAAJ&hl=zh-CN">Qiang Xu</a>.
                </div>
                <div class="conf">
                  European Conference on Computer Vision (<b>ECCV</b>), 2024
                </div>
                <div>
                  <span class="tag"> <a href="https://tencentarc.github.io/BrushNet/" target="_blank">Project</a> </span> /
                  <span class="tag"> <a href="https://arxiv.org/abs/2403.06976" target="_blank">arXiv</a> </span> /
                  <span class="tag"> <a href="https://drive.google.com/file/d/1IkEBWcd2Fui2WHcckap4QFPcCI0gkHBh/view" target="_blank">Video</a> </span> /
                  <span class="tag"> <a href="https://github.com/TencentARC/BrushNet" target="_blank">Code</a> </span> /
                  <span class="tag"> <a href="https://forms.gle/9TgMZ8tm49UYsZ9s5" target="_blank">Data</a> </span>
                  <img alt="GitHub Repo stars" src="https://img.shields.io/github/stars/TencentARC/BrushNet">
                </div>
              </td>
            </tr>
            

            <tr>
              <td width="30%">
                <img width="250" height="150" src="assets/figures/directinversion.png">
              </td>
              <td>
                <div class="title">
                  Direct Inversion: Boosting Diffusion-based Editing with 3 Lines of Code
                </div>
                <div class="author">
                  <span class="me">Xuan Ju</span>,
                  <a href="https://ailingzeng.site/">Ailing Zeng</a>,
                  <a href="https://scholar.google.com/citations?user=HzemVzoAAAAJ&hl=zh-CN&oi=ao">Yuxuan Bian</a>,
                  <a href="https://www.shaotengliu.com/">Shaoteng Liu</a>,
                  <a href="https://scholar.google.com/citations?user=eSiKPqUAAAAJ&hl=zh-CN">Qiang Xu</a>.
                </div>
                <div class="conf">
                  International Conference on Learning Representations (<b>ICLR</b>), 2024
                </div>
                <div>
                  <span class="tag"> <a href="https://cure-lab.github.io/DirectInversion/" target="_blank">Project</a> </span> /
                  <span class="tag"> <a href="https://arxiv.org/abs/2310.01506" target="_blank">arXiv</a> </span> /
                  <span class="tag"> <a href="https://drive.google.com/file/d/1HGr4ETPa7w-08KKOMhfxhngzQ9Y9Nj4H/view" target="_blank">Video</a> </span> /
                  <span class="tag"> <a href="https://github.com/cure-lab/DirectInversion" target="_blank">Code</a> </span> /
                  <span class="tag"> <a href="https://docs.google.com/forms/d/e/1FAIpQLSftGgDwLLMwrad9pX3Odbnd4UXGvcRuXDkRp6BT1nPk8fcH_g/viewform" target="_blank">Data</a> </span>
                  <img alt="GitHub Repo stars" src="https://img.shields.io/github/stars/cure-lab/DirectInversion">
                </div>
              </td>
            </tr>
            

            <tr>
              <td width="30%">
                <img width="250" height="150" src="assets/figures/humansd.png">
              </td>
              <td>
                <div class="title">
                  HumanSD: A Native Skeleton-Guided Diffusion Model for Human Image Generation
                </div>
                <div class="author">
                  <span class="me">Xuan Ju*</span>,
                  <a href="https://ailingzeng.site/">Ailing Zeng*</a>,
                  <a href="https://zcc31415926.github.io/">Chenchen Zhao*</a>,
                  <a href="https://scholar.google.com/citations?user=mt5mvZ8AAAAJ&hl=en">Jianan Wang</a>,
                  <a href="https://www.leizhang.org/">Lei Zhang</a>,
                  <a href="https://scholar.google.com/citations?user=eSiKPqUAAAAJ&hl=zh-CN">Qiang Xu</a>.
                </div>
                <div class="conf">
                  IEEE/CVF International Conference on Computer Vision (<b>ICCV</b>), 2023 <font color="red"> (Oral, Top 1.8%)</font>
                </div>
                <div>
                  <span class="tag"> <a href="https://idea-research.github.io/HumanSD/" target="_blank">Project</a> </span> /
                  <span class="tag"> <a href="https://arxiv.org/abs/2304.04269" target="_blank">arXiv</a> </span> /
                  <span class="tag"> <a href="https://drive.google.com/file/d/1Djc2uJS5fmKnKeBnL34FnAAm3YSH20Bb/view" target="_blank">Video</a> </span> /
                  <span class="tag"> <a href="https://github.com/IDEA-Research/HumanSD" target="_blank">Code</a> </span> /
                  <span class="tag"> <a href="https://forms.gle/ANxDTjxcE2Ua45oU8" target="_blank">Data</a> </span>
                  <img alt="GitHub Repo stars" src="https://img.shields.io/github/stars/IDEA-Research/HumanSD">
                </div>
              </td>
            </tr>
            
            <tr>
              <td width="30%">
                <img width="250" height="150" src="assets/figures/humanart.png">
              </td>
              <td>
                <div class="title">
                  Human-Art: A Versatile Human-Centric Dataset Bridging Natural and Artificial Scenes
                </div>
                <div class="author">
                  <span class="me">Xuan Ju*</span>,
                  <a href="https://ailingzeng.site/">Ailing Zeng*</a>,
                  <a href="https://scholar.google.com/citations?user=mt5mvZ8AAAAJ&hl=en">Jianan Wang</a>,
                  <a href="https://scholar.google.com/citations?user=eSiKPqUAAAAJ&hl=zh-CN">Qiang Xu</a>,
                  <a href="https://www.leizhang.org/">Lei Zhang</a>.
                </div>
                <div class="conf">
                  Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), 2023
                </div>
                <div>
                  <span class="tag"> <a href="https://idea-research.github.io/HumanArt/" target="_blank">Project</a> </span> /
                  <span class="tag"> <a href="https://arxiv.org/abs/2303.02760" target="_blank">arXiv</a> </span> /
                  <span class="tag"> <a href="https://www.youtube.com/watch?v=djmTKVlw53E" target="_blank">Video</a> </span> /
                  <span class="tag"> <a href="https://github.com/IDEA-Research/HumanArt" target="_blank">Code</a> </span> /
                  <span class="tag"> <a href="https://forms.gle/UVv1GiNJNQsE4qif7" target="_blank">Data</a> </span>
                  <img alt="GitHub Repo stars" src="https://img.shields.io/github/stars/IDEA-Research/HumanArt">
                </div>
              </td>
            </tr>

            
            <tr>
              <td width="30%">
                <img width="250" height="150" src="assets/figures/aLLM4TS.webp">
              </td>
              <td>
                <div class="title">
                  Multi-Patch Prediction: Adapting LLMs for Time Series Representation Learning
                </div>
                <div class="author">
                  <a href="https://yxbian23.github.io/">Yuxuan Bian*</a>,
                  <span class="me">Xuan Ju*</span>,
                  <a href="https://www.jiangtongli.me/">Jiangtong Li*</a>,
                  <a href="https://scholar.google.com/citations?user=MjlxzxcAAAAJ&hl=zh-CN&oi=ao">Zhijian Xu</a>,
                  <a href="http://cs1.tongji.edu.cn/~dawei/">Dawei Cheng</a>,
                  <a href="https://scholar.google.com/citations?user=eSiKPqUAAAAJ&hl=zh-CN">Qiang Xu</a>.
                </div>
                <div class="conf">
                  International Conference on Machine Learning (<b>ICML</b>), 2024
                </div>
                <div>
                  <span class="tag"> <a href="https://arxiv.org/abs/2402.04852" target="_blank">arXiv</a> </span>
                </div>
              </td>
            </tr>

          </tbody>        
          </table>
        </p>

        <h2>Working Experience</h2>
       
          <p style="margin:-20pt 0px">
          <table style="border-collapse:separate; border-spacing:10px 30px;" cellspacing="8">
          <tbody>

            <tr>
              <td width="33%">
                <img width="200" height="55" src="assets/figures/adobe.png">
              </td>
              <td>
                <div class="title">
                  Research Intern, Adobe Research
                </div>
                <!-- <div class="author">
                  Dec. 2024 - Mar. 2025
                </div> -->
                <div class="conf">
                  Topic: Multimodal Video Generation
                </div>
                <div>
                  Supervised by: <a href="https://sites.google.com/view/sooyekim">Soo Ye Kim</a> and <a href="https://scholar.google.com/citations?user=R0bnqaAAAAAJ&hl=en">Zhe Lin</a>
                </div>
              </td>
            </tr>

            <tr>
              <td width="33%">
                <img width="200" height="65" src="assets/figures/kuaishou.png">
              </td>
              <td>
                <div class="title">
                  Research Intern, Kuaishou Kling
                </div>
                <!-- <div class="author">
                  Dec. 2024 - Mar. 2025
                </div> -->
                <div class="conf">
                  Topic: Multimodal Video Generation
                </div>
                <div>
                  Supervised by: <a href="https://xinntao.github.io/">Xintao Wang</a>
                </div>
              </td>
            </tr>

            <tr>
              <td width="33%">
                <img width="200" height="90" src="assets/figures/meta.png">
              </td>
              <td>
                <div class="title">
                  Research Intern, Meta GenAI
                </div>
                <!-- <div class="author">
                  Jul. 2024 - Dec. 2024
                </div> -->
                <div class="conf">
                  Topic: Multimodal Image Generation
                </div>
                <div>
                  Supervised by: <a href="https://chihyaoma.github.io/">Kevin Chih-Yao Ma</a>
                </div>
              </td>
            </tr>

            <tr>
              <td width="33%">
                <img width="200" height="50" src="assets/figures/tencentarc.png">
              </td>
              <td>
                <div class="title">
                  Research Intern, Tencent ARC Laboratory
                </div>
                <!-- <div class="author">
                  Oct. 2023 - Jun. 2024
                </div> -->
                <div class="conf">
                  Topic: Image Inpainting, Video Generation
                </div>
                <div>
                  Supervised by: <a href="https://xinntao.github.io/">Xintao Wang</a>, <a href="https://scholar.google.com/citations?user=4oXBp9UAAAAJ">Ying Shan</a>
                </div>
              </td>
            </tr>

            <tr>
              <td width="23%">
                <img width="200" height="50" src="assets/figures/idea.jpeg">
              </td>
              <td>
                <div class="title">
                  Research Intern, International Digital Economy Academy (IDEA) CVR Laboratory
                </div>
                <!-- <div class="author">
                  Jun. 2022 - Oct. 2023
                </div> -->
                <div class="conf">
                  Topic: Human-Centric Image Generation
                </div>
                <div>
                  Supervised by: <a href="https://ailingzeng.site/">Ailing Zeng</a>, <a href="https://www.leizhang.org/">Lei Zhang</a></li>
                </div>
              </td>
            </tr>

            <tr>
              <td width="23%">
                <img width="200" height="50" src="assets/figures/sensetime.png">
              </td>
              <td>
                <div class="title">
                  Research Intern, X-Lab, SenseTime Research
                </div>
                <!-- <div class="author">
                  Dec. 2021 - May. 2022
                </div> -->
                <div class="conf">
                  Topic: Human Pose Estimation
                </div>
                <div>
                  Supervised by: <a href="https://scholar.google.com.hk/citations?user=jZH2IPYAAAAJ&hl=en">Lei Yang</a></li>
                </div>
              </td>
            </tr>

          </tbody>        
          </table>
        </p>

        <!-- <li><si> Research Intern, Creative Vision, Snap Research.</si>
        <br> May. 2023 - Sept. 2023
        <br> Topic: Human Generation Foundation Model.
        <br> Supervised by: <a href="https://alanspike.github.io/">Jian Ren</a>, <a href="https://aliaksandrsiarohin.github.io/aliaksandr-siarohin-website/">Aliaksandr Siarohin</a>, <a href="http://www.stulyakov.com/">Sergey Tulyakov</a>.</li>

        <li><si> Research Intern, Digital Content Group, Shanghai AI Laboratory.</si>
        <br> Jul. 2021 - Feb. 2022
        <br> Supervised by: <a href="http://daibo.info/">Bo Dai</a>.</li>
        <li>
        
        <si> Research Intern, Intelligent Video Group, SenseTime Research.</si>
        <br> Aug. 2020 - Jun. 2021
        <br> Supervised by: <a href="https://wywu.github.io/">Wayne Wu</a>.</li>
        </ul> -->
      
        </body>


</html>
