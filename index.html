<html>
    <head>
        <link rel="stylesheet" type="text/css" href="assets/font-awesome-4.7.0/css/font-awesome.min.css">
        <link rel="stylesheet" type="text/css" href="assets/academicons-1.8.6/css/academicons.min.css">
        <link rel="stylesheet" type="text/css" href="assets/style.css">
        <link rel="icon" type="image/png" href="assets/figures/icon.png">
        <link rel="apple-touch-icon" type="image/png" href="assets/figures/icon.png">
        <title>Yuxiang Zhao's Homepage </title>
    </head>
    
    <body><table border=0 width=1000px align=center><tr><td>
    
        <td valign="top">

        <br>
        <table style="font-size: 11pt;" border=0 width=100%>
            <tr>
                <td> 
                      <p style="text-align:left;font-size: 25pt;">
                        <name>Yuxiang Zhao</name>
                      </p>
                      <p style="text-align:left;font-size: 13pt;">
                        <font> 
                            Computer Vision Researcher<br>
                            Alibaba Group<br>
                            E-mail &nbsp/&nbsp
                            CV &nbsp/&nbsp
                            Google Scholar &nbsp/&nbsp
                            Github 
                        </font>
                      </p>
                </td>
                <td width = "20%">
                    <img src="assets/figures/avatar1.png" style="width: 53%; height: auto;">
                        </td>
            </tr>
        </table> 

        
        <!-- <font face="helvetica, ariel, 'sans serif'">  -->
        <h2>Biography</h2>
        <p style="line-height:15pt; font-size: 13pt; text-align: justify; margin:10pt 0px">
          Hi, I'm Yuxiang Zhao (赵煜翔). I am currently a Computer Vision Researcher at Alibaba Group, where I explore the cutting-edge frontiers of Embodied Artificial Intelligence. Prior to this role, I worked at Baidu, focusing on research related to conditional anime generation. I graduated from Sun Yat-sen University in 2024. My research aims to build multi-modal, human-like intelligent agents in a scalable manner—with a particular focus on training Large Motion Models to capture, understand, interact with, and generate the motions of humans, animals, and the broader physical world.
        </p>
        <!-- </font>        -->

        <h2>News</h2>
        <ul style="font-size: 14pt; text-align: justify;margin:10pt 0px"> 
        <li>[09/2025] <font color="black" size="3"> We release a unified image/video editing/generation framework, EditVerse. </font> </li>
        <li>[06/2025] <font color="black" size="3"> FullDiT (a multi-task video generation model based on full-attention) is accepted to ICCV 2025, see you in Hawai'i!</font> </li>
        <li>[05/2025] <font color="black" size="3"> We are hosting the CVPR 2025 Workshop on Efficient and On-Device Generation (EDGE). </font> </li>
        <li>[04/2025] <font color="black" size="3"> Start an internship in Adobe Research with Soo Ye Kim and Zhe Lin. </font> </li>
        <li>[04/2025] <font color="black" size="3"> VideoPainter and Cobra are accepted to SIGGRAPH 2025.</font> </li>
        </ul> 

        <h2>Working Experience</h2>
          <p style="margin:-20pt 0px">
          <table style="border-collapse:separate; border-spacing:10px 30px;" cellspacing="8">
          <tbody>

            <tr>
              <td width="33%">
                <img width="200" height="55" src="assets/figures/adobe.png">
              </td>
              <td>
                <div class="title">
                  Research Intern, Adobe Research
                </div>
                <div class="conf">
                  Topic: Multimodal Video Generation
                </div>
                <div>
                  Supervised by: Soo Ye Kim and Zhe Lin
                </div>
              </td>
            </tr>

            <tr>
              <td width="33%">
                <img width="200" height="65" src="assets/figures/kuaishou.png">
              </td>
              <td>
                <div class="title">
                  Research Intern, Kuaishou Kling
                </div>
                <div class="conf">
                  Topic: Multimodal Video Generation
                </div>
                <div>
                  Supervised by: Xintao Wang
                </div>
              </td>
            </tr>

            <tr>
              <td width="33%">
                <img width="200" height="90" src="assets/figures/meta.png">
              </td>
              <td>
                <div class="title">
                  Research Intern, Meta GenAI
                </div>
                <div class="conf">
                  Topic: Multimodal Image Generation
                </div>
                <div>
                  Supervised by: Kevin Chih-Yao Ma
                </div>
              </td>
            </tr>

          </tbody>        
          </table>
        </p>
        
        <h2>Selected Publications</h2>
        <p style="margin:-20pt 0px">
          <br/>
          <table style="border-collapse:separate; border-spacing:0px 35px;" cellspacing="8">
          <tbody>

            <tr>
              <td width="30%">
                <img width="250" height="150" src="assets/figures/editverse.png">
              </td>
              <td>
                <div class="title">
                  EditVerse: Unifying Image and Video Editing and Generation with In-Context Learning
                </div>
                <div class="author">
                  Xuan Ju,
                  Tianyu Wang,
                  Yuqian Zhou,
                  He Zhang,
                  Qing Liu,
                  Nanxuan Zhao,
                  Zhifei Zhang,
                  Yijun Li,
                  Yuanhao Cai,
                  Shaoteng Liu,
                  Daniil Pakhomov,
                  Zhe Lin,
                  Soo Ye Kim,
                  Qiang Xu.
                </div>
                <div class="conf">
                  Under Review
                </div>
                <div>
                  <span class="tag"> Project </span> /
                  <span class="tag"> arXiv </span> /
                  <span class="tag"> Code </span> /
                  <span class="tag"> Benchmark </span> /
                  <span class="tag"> Slides </span> / 
                  <span class="tag"> Full Comparison </span>
                </div>
              </td>
            </tr>
            

            <tr>
              <td width="30%">
                <img width="250" height="130" src="assets/figures/fulldit.png">
              </td>
              <td>
                <div class="title">
                  FullDiT: Multi-Task Video Generative Foundation Model with Full Attention
                </div>
                <div class="author">
                  Xuan Ju,
                  Weicai Ye,
                  Quande Liu,
                  Qiulin Wang,
                  Xintao Wang,
                  Pengfei Wan,
                  Di Zhang,
                  Kun Gai,
                  Qiang Xu.
                </div>
                <div class="conf">
                  International Conference on Computer Vision (ICCV), 2025
                </div>
                <div>
                  <span class="tag"> Project </span> /
                  <span class="tag"> arXiv </span> /
                  <span class="tag"> Video </span> /
                  <span class="tag"> Data </span>
                </div>
              </td>
            </tr>

          </tbody>        
          </table>
        </p>
        </body>


</html>
